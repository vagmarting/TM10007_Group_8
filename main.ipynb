{"cells":[{"cell_type":"markdown","metadata":{},"source":["### Import"]},{"cell_type":"code","execution_count":350,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import os\n","from sklearn.model_selection import train_test_split, cross_val_score, learning_curve, RandomizedSearchCV\n","from sklearn.linear_model import SGDClassifier, LogisticRegression\n","from sklearn.preprocessing import StandardScaler\n","from sklearn import metrics\n","from sklearn import neighbors\n","from sklearn.feature_selection import SelectFromModel, SelectKBest, f_classif, VarianceThreshold\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn import metrics\n","from matplotlib import pyplot\n"]},{"cell_type":"markdown","metadata":{},"source":["### Load data"]},{"cell_type":"code","execution_count":351,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["The number of samples: 113\n","The number of columns: 159\n"]}],"source":["def load_data():\n","    data = pd.read_csv(os.path.join('hn', 'HN_radiomicFeatures.csv'), index_col=0)\n","    label = data[\"label\"]\n","    data = data.drop([\"label\"], axis=1)\n","    feature_names = data.columns.values\n","    return data, label, feature_names\n","\n","data, label, feature_names = load_data()\n","print(f'The number of samples: {len(data.index)}')\n","print(f'The number of columns: {len(data.columns)}')\n"]},{"cell_type":"markdown","metadata":{},"source":["### Check for missing data"]},{"cell_type":"code","execution_count":352,"metadata":{},"outputs":[{"data":{"text/plain":["False"]},"execution_count":352,"metadata":{},"output_type":"execute_result"}],"source":["# Detect missing values in dataframe\n","data.isnull().values.any()"]},{"cell_type":"markdown","metadata":{},"source":["### Data split"]},{"cell_type":"code","execution_count":353,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["The number of train samples: 90\n","The number of test samples: 23\n"]}],"source":["def split_data(data, label):\n","    train_data, test_data, train_label, test_label = train_test_split(data, label, train_size=0.8)\n","    return train_data, test_data, train_label, test_label\n","# train_data, val_data, train_label, val_label = train_test_split(train_val_data, train_val_label, train_size=0.85)\n","\n","train_data, test_data, train_label, test_label = split_data(data, label)\n","print(f'The number of train samples: {train_data.shape[0]}')\n","# print(f'The number of validation samples: {val_data.shape[0]}')\n","print(f'The number of test samples: {test_data.shape[0]}')"]},{"cell_type":"markdown","metadata":{},"source":["### Scaling train data"]},{"cell_type":"code","execution_count":354,"metadata":{},"outputs":[],"source":["def scale_data(train_data, test_data, feature_names):\n","    scaler = StandardScaler().fit(train_data)\n","    train_data = scaler.transform(train_data)\n","    test_data = scaler.transform(test_data)\n","    train_data = pd.DataFrame(train_data, columns=feature_names)\n","    test_data = pd.DataFrame(test_data, columns=feature_names)\n","    return train_data, test_data"]},{"cell_type":"markdown","metadata":{},"source":["### Remove features with 0 variance"]},{"cell_type":"code","execution_count":355,"metadata":{},"outputs":[],"source":["def remove_zero_var(train_data, test_data):\n","    selector = VarianceThreshold()\n","    selector.fit_transform(train_data)\n","    zero_var_col = [column for column in train_data.columns if column not in train_data.columns[selector.get_support()]]\n","    train_data.drop(zero_var_col, inplace=True, axis=1)\n","    test_data.drop(zero_var_col, inplace=True, axis=1)\n","    return train_data, test_data"]},{"cell_type":"markdown","metadata":{},"source":["### Select best features with Anova test"]},{"cell_type":"code","execution_count":356,"metadata":{},"outputs":[],"source":["def select_features(kbest, train_data, train_label, test_data):\n","    fs = SelectKBest(score_func=f_classif, k=kbest)\n","    kbest_train = fs.fit_transform(train_data, train_label)\n","    kbest_test = fs.transform(test_data)\n","    return kbest_train, kbest_test"]},{"cell_type":"markdown","metadata":{},"source":["### Lasso Regression"]},{"cell_type":"code","execution_count":357,"metadata":{},"outputs":[],"source":["def lasso_regression(train_data, train_label, test_data):\n","    sel_ = SelectFromModel(LogisticRegression(C=1, penalty='l1', solver='liblinear'))\n","    sel_.fit(train_data, np.ravel(train_label,order='C'))\n","    sel_.get_support()\n","    train_data = pd.DataFrame(train_data)\n","    test_data = pd.DataFrame(test_data)\n","    removed_feats = train_data.columns[(sel_.estimator_.coef_ == 0).ravel().tolist()]\n","    lasso_train = train_data.drop(removed_feats, axis='columns')\n","    lasso_test = test_data.drop(removed_feats, axis='columns')\n","    return lasso_train, lasso_test"]},{"cell_type":"markdown","metadata":{},"source":["### Linear Classifier"]},{"cell_type":"code","execution_count":358,"metadata":{},"outputs":[],"source":["def linear_classifier(train_data, test_data, train_label, test_label):\n","    clf = SGDClassifier()\n","    clf.fit(train_data, train_label)\n","\n","    train_linear = clf.predict(train_data)\n","    score_linear_train = metrics.accuracy_score(train_label, train_linear)\n","\n","    test_linear = clf.predict(test_data)\n","    score_linear_test = metrics.accuracy_score(test_label, test_linear)\n","    return score_linear_train, score_linear_test"]},{"cell_type":"markdown","metadata":{},"source":["### kNN classifier"]},{"cell_type":"code","execution_count":359,"metadata":{},"outputs":[],"source":["def knn_classifier(train_pca, test_pca, train_label, test_label, knn_neighbors):\n","    knn = neighbors.KNeighborsClassifier(n_neighbors=knn_neighbors)\n","    knn.fit(train_pca, train_label)\n","    score_train = knn.score(train_pca, train_label)\n","    score_test = knn.score(test_pca, test_label)\n","    return score_train, score_test"]},{"cell_type":"markdown","metadata":{},"source":["### Random Forest Classifier"]},{"cell_type":"code","execution_count":360,"metadata":{},"outputs":[],"source":["\"\"\"\n","for i in max_depth:\n","    clf=RandomForestClassifier(n_estimators=20, max_depth=i)\n","    rf_score = cross_val_score(clf, train_data, train_label, cv=7)\n","    mean_rf_score.append(np.mean(rf_score))\n","    std_rf_score.append(np.std(rf_score))\n","\"\"\"\n","\n","#print(f\"Mean rf score per depth: {mean_rf_score}\")\n","#print(f\"Standard deviation: {std_rf_score}\")\n","# clf = RandomForestClassifier(n_estimators=20, max_depth=2)\n","# learning_curve(clf, train_data, train_label, cv=5, scoring=None)\n","# n_jobs=-1, train_sizes=np.linspace(0.01, 1.0, 50)    \n","\n","def random_forest2(train_data, test_data, train_label, test_label):\n","    clf = RandomForestClassifier()\n","    n_estimators = range(20,140,15)\n","    max_depth = range(8, 15, 2)\n","    min_samples_leaf = range(2, 7)\n","    min_samples_split = range(3, 10, 2)\n","\n","    param_grid = {\n","        'n_estimators': n_estimators,\n","        'max_depth': max_depth,\n","        'min_samples_leaf': min_samples_leaf,\n","        'min_samples_split': min_samples_split\n","    }\n","\n","    rf_random = RandomizedSearchCV(estimator=clf, param_distributions=param_grid, n_iter=50, cv=5)\n","    rf_random.fit(train_data, train_label)\n","    print(rf_random.best_params_)\n","    \n","    best_params = rf_random.best_params_\n","    best_model = RandomForestClassifier(n_estimators=best_params['n_estimators'], min_samples_split=best_params['min_samples_split'],\n","                                    min_samples_leaf=best_params['min_samples_leaf'], max_depth=best_params['max_depth'])\n","    best_model.fit(train_data,train_label)\n","    rf_random_train =  best_model.predict(train_data)\n","    rf_random_test = best_model.predict(test_data)\n","    score_train = metrics.accuracy_score(train_label, rf_random_train)\n","    score_test = metrics.accuracy_score(test_label, rf_random_test)\n","    return score_train, score_test"]},{"cell_type":"code","execution_count":361,"metadata":{},"outputs":[],"source":["def random_forest(train_data, test_data, train_label, test_label):\n","    clf=RandomForestClassifier(n_estimators=20)\n","    clf.fit(train_data,train_label)\n","    test_random_forest = clf.predict(test_data)\n","    train_random_forest =  clf.predict(train_data)\n","    score_test = metrics.accuracy_score(test_label, test_random_forest)\n","    score_train = metrics.accuracy_score(train_label, train_random_forest)\n","    return score_train, score_test"]},{"cell_type":"markdown","metadata":{},"source":["### Find average accuracy over multiple classifications"]},{"cell_type":"code","execution_count":362,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["{'n_estimators': 50, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_depth': 14}\n","{'n_estimators': 80, 'min_samples_split': 9, 'min_samples_leaf': 5, 'max_depth': 8}\n","{'n_estimators': 80, 'min_samples_split': 3, 'min_samples_leaf': 6, 'max_depth': 12}\n","{'n_estimators': 50, 'min_samples_split': 7, 'min_samples_leaf': 2, 'max_depth': 14}\n","{'n_estimators': 65, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_depth': 12}\n","{'n_estimators': 50, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_depth': 14}\n","{'n_estimators': 125, 'min_samples_split': 7, 'min_samples_leaf': 6, 'max_depth': 12}\n","{'n_estimators': 80, 'min_samples_split': 7, 'min_samples_leaf': 2, 'max_depth': 8}\n","{'n_estimators': 20, 'min_samples_split': 5, 'min_samples_leaf': 6, 'max_depth': 8}\n","{'n_estimators': 65, 'min_samples_split': 9, 'min_samples_leaf': 2, 'max_depth': 8}\n","Mean training score: 0.9355555555555556\n","Mean test score: 0.7391304347826086\n"]}],"source":["# Find mean accuracy for kNN classification\n","loops = 10\n","score_train_array = np.zeros(loops)\n","score_test_array = np.zeros(loops)\n","num_best_features = 80\n","pca_components = 10\n","knn_neighbors = 15\n","\n","for i in range(loops):\n","    data, label, feature_names = load_data()\n","    train_data, test_data, train_label, test_label = split_data(data, label)\n","    train_data, test_data = scale_data(train_data, test_data, feature_names)\n","    train_data, test_data = remove_zero_var(train_data, test_data)\n","\n","    # Find best features based on F-scores\n","    kbest_train, kbest_test = select_features(num_best_features, train_data, train_label, test_data)\n","\n","    # Lasso regression\n","    lasso_train, lasso_test = lasso_regression(kbest_train, train_label, kbest_test)\n","\n","    # Fit kNN\n","    # score_train, score_test = knn_classifier(train_pca, test_pca, train_label, test_label, knn_neighbors)\n","    # score_train, score_test = linear_classifier(kbest_train, kbest_test, train_label, test_label)\n","    score_train, score_test = random_forest2(lasso_train, lasso_test, train_label, test_label)\n","    score_train_array[i] = score_train\n","    score_test_array[i] = score_test\n","\n","\n","mean_score_train = np.mean(score_train_array)\n","mean_score_test = np.mean(score_test_array)\n","print(f\"Mean training score: {mean_score_train}\")\n","print(f\"Mean test score: {mean_score_test}\")"]}],"metadata":{"interpreter":{"hash":"b06a8b1b5357041cc42e80e2521eaa7af7af6411ea3b8d26843f925cac4959c7"},"kernelspec":{"display_name":"Python 3.9.5 ('base')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
