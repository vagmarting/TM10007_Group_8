{"cells":[{"cell_type":"markdown","metadata":{},"source":["### Import"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import os\n","from sklearn.model_selection import train_test_split, cross_val_score, learning_curve, RandomizedSearchCV\n","from sklearn.linear_model import SGDClassifier, LogisticRegression\n","from sklearn.preprocessing import StandardScaler\n","from sklearn import metrics\n","from sklearn import neighbors\n","from sklearn.feature_selection import SelectFromModel, SelectKBest, f_classif, VarianceThreshold\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn import metrics\n","from matplotlib import pyplot\n"]},{"cell_type":"markdown","metadata":{},"source":["### Load data"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["The number of samples: 113\n","The number of columns: 159\n"]}],"source":["def load_data():\n","    data = pd.read_csv(os.path.join('hn', 'HN_radiomicFeatures.csv'), index_col=0)\n","    label = data[\"label\"]\n","    label = label.replace(to_replace={'T12': False, 'T34': True}, value=None)\n","    data = data.drop([\"label\"], axis=1)\n","    feature_names = data.columns.values\n","    return data, label, feature_names\n","\n","data, label, feature_names = load_data()\n","print(f'The number of samples: {len(data.index)}')\n","print(f'The number of columns: {len(data.columns)}')\n"]},{"cell_type":"markdown","metadata":{},"source":["### Check for missing data"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"data":{"text/plain":["False"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["# Detect missing values in dataframe\n","data.isnull().values.any()"]},{"cell_type":"markdown","metadata":{},"source":["### Data split"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["The number of train samples: 79\n","The number of test samples: 34\n"]}],"source":["def split_data(data, label):\n","    train_data, test_data, train_label, test_label = train_test_split(data, label, train_size=0.7)\n","    return train_data, test_data, train_label, test_label\n","# train_data, val_data, train_label, val_label = train_test_split(train_val_data, train_val_label, train_size=0.85)\n","\n","train_data, test_data, train_label, test_label = split_data(data, label)\n","print(f'The number of train samples: {train_data.shape[0]}')\n","# print(f'The number of validation samples: {val_data.shape[0]}')\n","print(f'The number of test samples: {test_data.shape[0]}')"]},{"cell_type":"markdown","metadata":{},"source":["### Scaling train data"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["def scale_data(train_data, test_data, feature_names):\n","    scaler = StandardScaler().fit(train_data)\n","    train_data = scaler.transform(train_data)\n","    test_data = scaler.transform(test_data)\n","    train_data = pd.DataFrame(train_data, columns=feature_names)\n","    test_data = pd.DataFrame(test_data, columns=feature_names)\n","    return train_data, test_data"]},{"cell_type":"markdown","metadata":{},"source":["### Remove features with 0 variance"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["def remove_zero_var(train_data, test_data):\n","    selector = VarianceThreshold()\n","    selector.fit_transform(train_data)\n","    zero_var_col = [column for column in train_data.columns if column not in train_data.columns[selector.get_support()]]\n","    train_data.drop(zero_var_col, inplace=True, axis=1)\n","    test_data.drop(zero_var_col, inplace=True, axis=1)\n","    return train_data, test_data"]},{"cell_type":"markdown","metadata":{},"source":["### Select best features with Anova test"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["def select_features(kbest, train_data, train_label, test_data):\n","    fs = SelectKBest(score_func=f_classif, k=kbest)\n","    kbest_train = fs.fit_transform(train_data, train_label)\n","    kbest_test = fs.transform(test_data)\n","    return kbest_train, kbest_test"]},{"cell_type":"markdown","metadata":{},"source":["### Lasso Regression"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["def lasso_regression(train_data, train_label, test_data):\n","    sel_ = SelectFromModel(LogisticRegression(C=1, penalty='l1', solver='liblinear'))\n","    sel_.fit(train_data, np.ravel(train_label,order='C'))\n","    sel_.get_support()\n","    train_data = pd.DataFrame(train_data)\n","    test_data = pd.DataFrame(test_data)\n","    removed_feats = train_data.columns[(sel_.estimator_.coef_ == 0).ravel().tolist()]\n","    lasso_train = train_data.drop(removed_feats, axis='columns')\n","    lasso_test = test_data.drop(removed_feats, axis='columns')\n","    return lasso_train, lasso_test"]},{"cell_type":"markdown","metadata":{},"source":["### Random Forest Classifier"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["def random_forest(train_data, test_data, train_label, test_label):\n","    clf = RandomForestClassifier()\n","    n_estimators = range(20,140,15)\n","    max_depth = range(8, 15, 2)\n","    min_samples_leaf = range(2, 7)\n","    min_samples_split = range(3, 10, 2)\n","\n","    param_grid = {\n","        'n_estimators': n_estimators,\n","        'max_depth': max_depth,\n","        'min_samples_leaf': min_samples_leaf,\n","        'min_samples_split': min_samples_split\n","    }\n","\n","    rf_random = RandomizedSearchCV(estimator=clf, param_distributions=param_grid, n_iter=150, cv=4)\n","    rf_random.fit(train_data, train_label)\n","    \n","    best_params = rf_random.best_params_\n","    best_model = RandomForestClassifier(n_estimators=best_params['n_estimators'], min_samples_split=best_params['min_samples_split'],\n","                                    min_samples_leaf=best_params['min_samples_leaf'], max_depth=best_params['max_depth'])\n","    best_model.fit(train_data,train_label)\n","    rf_random_train =  best_model.predict(train_data)\n","    rf_random_test = best_model.predict(test_data)\n","    score_train = metrics.accuracy_score(train_label, rf_random_train)\n","    score_test = metrics.accuracy_score(test_label, rf_random_test)\n","    confusion_matrix_train = metrics.confusion_matrix(train_label, rf_random_train)\n","    confusion_matrix_test = metrics.confusion_matrix(test_label, rf_random_test)\n","    return score_train, score_test, confusion_matrix_train, confusion_matrix_test"]},{"cell_type":"markdown","metadata":{},"source":["### Calculate sensitivity, specificity, PPV, NPV"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["def sens_spec(confusion_matrix):\n","    true_neg, false_pos, false_neg, true_pos = confusion_matrix.ravel()\n","\n","    sens = true_pos/(true_pos + false_neg)\n","    spec = true_neg/(true_neg + false_pos)\n","    pos_pred_value = true_pos/(true_pos + false_pos)\n","    neg_pred_value = true_neg/(true_neg + false_neg)\n","    return sens, spec, pos_pred_value, neg_pred_value"]},{"cell_type":"markdown","metadata":{},"source":["### Find average accuracy over multiple classifications"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Mean training score: 0.9405063291139241\n","Mean test score: 0.7372549019607845\n","Mean train sens: 0.8611111111111112\n","Mean test sens: 0.6842105263157895\n","Mean train spec: 0.9767441860465116\n","Mean test spec: 0.8666666666666667\n","Mean train PPV 0.96875\n","Mean test PPV: 0.8666666666666667\n","Mean train NPV: 0.8936170212765957\n","Mean test NPV: 0.6842105263157895\n"]}],"source":["# Find mean accuracy for kNN classification\n","loops = 30\n","score_train_array = np.zeros(loops)\n","score_test_array = np.zeros(loops)\n","sens_train_array = np.zeros(loops)\n","spec_train_array = np.zeros(loops)\n","pos_pred_value_train_array = np.zeros(loops)\n","neg_pred_value_train_array = np.zeros(loops)\n","sens_test_array = np.zeros(loops)\n","spec_test_array = np.zeros(loops)\n","pos_pred_value_test_array = np.zeros(loops)\n","neg_pred_value_test_array = np.zeros(loops)\n","\n","num_best_features = 80\n","pca_components = 10\n","knn_neighbors = 15\n","\n","for i in range(loops):\n","    data, label, feature_names = load_data()\n","    train_data, test_data, train_label, test_label = split_data(data, label)\n","    train_data, test_data = scale_data(train_data, test_data, feature_names)\n","    train_data, test_data = remove_zero_var(train_data, test_data)\n","\n","    # Find best features based on F-scores\n","    kbest_train, kbest_test = select_features(num_best_features, train_data, train_label, test_data)\n","\n","    # Lasso regression\n","    lasso_train, lasso_test = lasso_regression(kbest_train, train_label, kbest_test)\n","\n","    # Apply random forest classifier\n","    score_train, score_test, confusion_matrix_train, confusion_matrix_test = random_forest(lasso_train, lasso_test, train_label, test_label)\n","    score_train_array[i] = score_train\n","    score_test_array[i] = score_test\n","\n","    sens_train, spec_train, pos_pred_value_train, neg_pred_value_train = sens_spec(confusion_matrix_train)\n","    sens_test, spec_test, pos_pred_value_test, neg_pred_value_test = sens_spec(confusion_matrix_test)\n","\n","    sens_train_array[i] = sens_train\n","    spec_train_array[i] = spec_train\n","    pos_pred_value_train_array[i] = pos_pred_value_train\n","    neg_pred_value_train_array[i] = neg_pred_value_train\n","\n","    sens_test_array[i] = sens_test\n","    spec_test_array[i] = spec_test\n","    pos_pred_value_test_array[i] = pos_pred_value_test\n","    neg_pred_value_test_array[i] = neg_pred_value_test\n","\n","\n","mean_score_train = np.mean(score_train_array)\n","mean_score_test = np.mean(score_test_array)\n","mean_sens_train = np.mean(sens_train)\n","mean_spec_train = np.mean(spec_train)\n","mean_ppv_train = np.mean(pos_pred_value_train)\n","mean_npv_train = np.mean(neg_pred_value_train)\n","mean_sens_test = np.mean(sens_test)\n","mean_spec_test = np.mean(spec_test)\n","mean_ppv_test = np.mean(pos_pred_value_test)\n","mean_npv_test = np.mean(neg_pred_value_test)\n","\n","print(f\"Mean training score: {mean_score_train}\")\n","print(f\"Mean test score: {mean_score_test}\")\n","print(f\"Mean train sens: {mean_sens_train}\")\n","print(f\"Mean test sens: {mean_sens_test}\")\n","print(f\"Mean train spec: {mean_spec_train}\")\n","print(f\"Mean test spec: {mean_spec_test}\")\n","print(f\"Mean train PPV {mean_ppv_train}\")\n","print(f\"Mean test PPV: {mean_ppv_test}\")\n","print(f\"Mean train NPV: {mean_npv_train}\")\n","print(f\"Mean test NPV: {mean_npv_test}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"interpreter":{"hash":"b06a8b1b5357041cc42e80e2521eaa7af7af6411ea3b8d26843f925cac4959c7"},"kernelspec":{"display_name":"Python 3.9.5 ('base')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.5"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
